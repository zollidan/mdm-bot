Directory structure:
‚îî‚îÄ‚îÄ zollidan-mdm-bot/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ alembic.ini
    ‚îú‚îÄ‚îÄ docker-compose.yml
    ‚îú‚îÄ‚îÄ pyproject.toml
    ‚îú‚îÄ‚îÄ .python-version
    ‚îî‚îÄ‚îÄ bot/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ config.py
        ‚îú‚îÄ‚îÄ main.py
        ‚îú‚îÄ‚îÄ dao/
        ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
        ‚îÇ   ‚îú‚îÄ‚îÄ base.py
        ‚îÇ   ‚îú‚îÄ‚îÄ dao.py
        ‚îÇ   ‚îú‚îÄ‚îÄ database.py
        ‚îÇ   ‚îú‚îÄ‚îÄ database_middleware.py
        ‚îÇ   ‚îî‚îÄ‚îÄ models.py
        ‚îú‚îÄ‚îÄ migration/
        ‚îÇ   ‚îú‚îÄ‚îÄ README
        ‚îÇ   ‚îú‚îÄ‚îÄ env.py
        ‚îÇ   ‚îú‚îÄ‚îÄ script.py.mako
        ‚îÇ   ‚îî‚îÄ‚îÄ versions/
        ‚îÇ       ‚îú‚îÄ‚îÄ 8fe99a9f0146_new_products.py
        ‚îÇ       ‚îî‚îÄ‚îÄ d14ca4f76ccf_add_favorites_table.py
        ‚îî‚îÄ‚îÄ user/
            ‚îú‚îÄ‚îÄ __init__.py
            ‚îú‚îÄ‚îÄ kbs.py
            ‚îú‚îÄ‚îÄ schemas.py
            ‚îî‚îÄ‚îÄ user_router.py

================================================
FILE: README.md
================================================
[Empty file]


================================================
FILE: __init__.py
================================================
[Empty file]


================================================
FILE: alembic.ini
================================================
# A generic, single database configuration.

[alembic]
# path to migration scripts.
# Use forward slashes (/) also on windows to provide an os agnostic path
script_location = bot/migration

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to migration/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:migration/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
# version_path_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
version_path_separator = os

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

sqlalchemy.url = driver://user:pass@localhost/dbname


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S



================================================
FILE: docker-compose.yml
================================================
version: "3.9"

services:
  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_DB: ${DATABASE_NAME}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:



================================================
FILE: pyproject.toml
================================================
[project]
name = "mdm-bot"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "aiogram>=3.19.0",
    "aiosqlite>=0.21.0",
    "alembic>=1.15.2",
    "art>=6.4",
    "asyncpg>=0.30.0",
    "loguru>=0.7.3",
    "pydantic>=2.10.6",
    "pydantic-settings>=2.8.1",
    "sqlalchemy>=2.0.40",
]

[tool.ruff]
exclude = [
    "bot/migration/env.py",
]



================================================
FILE: .python-version
================================================
3.10



================================================
FILE: bot/__init__.py
================================================
[Empty file]


================================================
FILE: bot/config.py
================================================
import os
from typing import List
from loguru import logger
from aiogram import Bot, Dispatcher
from aiogram.enums import ParseMode
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.client.default import DefaultBotProperties
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    BOT_TOKEN: str
    ADMIN_IDS: List[int]
    FORMAT_LOG: str = "{time:YYYY-MM-DD at HH:mm:ss} | {level} | {message}"
    LOG_ROTATION: str = "10 MB"
    DATABASE_USER: str
    DATABASE_PASSWORD: str
    DATABASE_NAME: str
    model_config = SettingsConfigDict(
        env_file=os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", ".env")
    )

settings = Settings()

bot = Bot(token=settings.BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher(storage=MemoryStorage())
admins = settings.ADMIN_IDS

log_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "log.txt")
logger.add(log_file_path, format=settings.FORMAT_LOG, level="INFO", rotation=settings.LOG_ROTATION)
database_url = f"postgresql+asyncpg://{settings.DATABASE_USER}:{settings.DATABASE_PASSWORD}@localhost/{settings.DATABASE_NAME}"


================================================
FILE: bot/main.py
================================================
from os.path import abspath, dirname
import sys

sys.path.insert(0, dirname(dirname(abspath(__file__))))

import asyncio
from aiogram.types import BotCommand, BotCommandScopeDefault
from loguru import logger

from bot.config import bot, admins, dp
from bot.dao.database_middleware import DatabaseMiddlewareWithoutCommit, DatabaseMiddlewareWithCommit
from bot.user.user_router import user_router

from art import tprint

# –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç –∫–æ–º–∞–Ω–¥–Ω–æ–µ –º–µ–Ω—é (–¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)
async def set_commands():
    commands = [BotCommand(command='start', description='–°—Ç–∞—Ä—Ç')]
    await bot.set_my_commands(commands, BotCommandScopeDefault())



async def main():
    
    tprint("mdm-bot")
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–∏–¥–ª–≤–∞—Ä–µ–π
    dp.update.middleware.register(DatabaseMiddlewareWithoutCommit())
    dp.update.middleware.register(DatabaseMiddlewareWithCommit())

    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ä–æ—É—Ç–µ—Ä–æ–≤
    dp.include_router(user_router)

    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ long polling
    try:
        await bot.delete_webhook(drop_pending_updates=True)
        await dp.start_polling(bot, allowed_updates=dp.resolve_used_update_types())
    finally:
        await bot.session.close()

if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: bot/dao/__init__.py
================================================
[Empty file]


================================================
FILE: bot/dao/base.py
================================================
from typing import TypeVar, Generic
from pydantic import BaseModel
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.future import select
from sqlalchemy import delete as sqlalchemy_delete, func
from loguru import logger
from sqlalchemy.ext.asyncio import AsyncSession

from bot.dao.database import Base

# –û–±—ä—è–≤–ª—è–µ–º —Ç–∏–ø–æ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä T —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫ Base
T = TypeVar("T", bound=Base)


class BaseDAO(Generic[T]):
    model: type[T]

    @classmethod
    async def find_one_or_none_by_id(cls, data_id: int, session: AsyncSession):
        # –ù–∞–π—Ç–∏ –∑–∞–ø–∏—Å—å –ø–æ ID
        logger.info(f"–ü–æ–∏—Å–∫ {cls.model.__name__} —Å ID: {data_id}")
        try:
            query = select(cls.model).filter_by(id=data_id)
            result = await session.execute(query)
            record = result.scalar_one_or_none()
            if record:
                logger.info(f"–ó–∞–ø–∏—Å—å —Å ID {data_id} –Ω–∞–π–¥–µ–Ω–∞.")
            else:
                logger.info(f"–ó–∞–ø–∏—Å—å —Å ID {data_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            return record
        except SQLAlchemyError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∑–∞–ø–∏—Å–∏ —Å ID {data_id}: {e}")
            raise

    @classmethod
    async def find_one_or_none(cls, session: AsyncSession, filters: BaseModel):
        # –ù–∞–π—Ç–∏ –æ–¥–Ω—É –∑–∞–ø–∏—Å—å –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º
        filter_dict = filters.model_dump(exclude_unset=True)
        logger.info(f"–ü–æ–∏—Å–∫ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ {cls.model.__name__} –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º: {filter_dict}")
        try:
            query = select(cls.model).filter_by(**filter_dict)
            result = await session.execute(query)
            record = result.scalar_one_or_none()
            if record:
                logger.info(f"–ó–∞–ø–∏—Å—å –Ω–∞–π–¥–µ–Ω–∞ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º: {filter_dict}")
            else:
                logger.info(f"–ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º: {filter_dict}")
            return record
        except SQLAlchemyError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∑–∞–ø–∏—Å–∏ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º {filter_dict}: {e}")
            raise

    @classmethod
    async def find_all(cls, session: AsyncSession, filters: BaseModel | None = None):
        # –ù–∞–π—Ç–∏ –≤—Å–µ –∑–∞–ø–∏—Å–∏ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º
        filter_dict = filters.model_dump(exclude_unset=True) if filters else {}
        logger.info(f"–ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π {cls.model.__name__} –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º: {filter_dict}")
        try:
            query = select(cls.model).filter_by(**filter_dict)
            result = await session.execute(query)
            records = result.scalars().all()
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(records)} –∑–∞–ø–∏—Å–µ–π.")
            return records
        except SQLAlchemyError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º {filter_dict}: {e}")
            raise

    @classmethod
    async def add(cls, session: AsyncSession, values: BaseModel):
        # –î–æ–±–∞–≤–∏—Ç—å –æ–¥–Ω—É –∑–∞–ø–∏—Å—å
        values_dict = values.model_dump(exclude_unset=True)
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ {cls.model.__name__} —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: {values_dict}")
        new_instance = cls.model(**values_dict)
        session.add(new_instance)
        try:
            await session.flush()
            logger.info(f"–ó–∞–ø–∏—Å—å {cls.model.__name__} —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞.")
        except SQLAlchemyError as e:
            await session.rollback()
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–∏: {e}")
            raise e
        return new_instance

    @classmethod
    async def delete(cls, session: AsyncSession, filters: BaseModel):
        # –£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ –ø–æ —Ñ–∏–ª—å—Ç—Ä—É
        filter_dict = filters.model_dump(exclude_unset=True)
        logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π {cls.model.__name__} –ø–æ —Ñ–∏–ª—å—Ç—Ä—É: {filter_dict}")
        if not filter_dict:
            logger.error("–ù—É–∂–µ–Ω —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
            raise ValueError("–ù—É–∂–µ–Ω —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")

        query = sqlalchemy_delete(cls.model).filter_by(**filter_dict)
        try:
            result = await session.execute(query)
            await session.flush()
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ {result.rowcount} –∑–∞–ø–∏—Å–µ–π.")
            return result.rowcount
        except SQLAlchemyError as e:
            await session.rollback()
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–µ–π: {e}")
            raise e

    @classmethod
    async def count(cls, session: AsyncSession, filters: BaseModel | None = None):
        # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        filter_dict = filters.model_dump(exclude_unset=True) if filters else {}
        logger.info(f"–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π {cls.model.__name__} –ø–æ —Ñ–∏–ª—å—Ç—Ä—É: {filter_dict}")
        try:
            query = select(func.count(cls.model.id)).filter_by(**filter_dict)
            result = await session.execute(query)
            count = result.scalar()
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π.")
            return count
        except SQLAlchemyError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ –∑–∞–ø–∏—Å–µ–π: {e}")
            raise


================================================
FILE: bot/dao/dao.py
================================================
[Binary file]


================================================
FILE: bot/dao/database.py
================================================
from datetime import datetime
from bot.config import database_url
from sqlalchemy import func, TIMESTAMP, Integer
from sqlalchemy.orm import Mapped, mapped_column, DeclarativeBase
from sqlalchemy.ext.asyncio import AsyncAttrs, async_sessionmaker, create_async_engine, AsyncSession

# –°–æ–∑–¥–∞–Ω–∏–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –¥–≤–∏–∂–∫–∞ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
engine = create_async_engine(url=database_url)

# –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–±—Ä–∏–∫–∏ —Å–µ—Å—Å–∏–π
async_session_maker = async_sessionmaker(engine, class_=AsyncSession)

# –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–µ–π
class Base(AsyncAttrs, DeclarativeBase):
    __abstract__ = True  # –≠—Ç–æ—Ç –∫–ª–∞—Å—Å –Ω–µ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É

    # –û–±—â–µ–µ –ø–æ–ª–µ "id" –¥–ª—è –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)

    # –ü–æ–ª—è –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏
    created_at: Mapped[datetime] = mapped_column(
        TIMESTAMP, server_default=func.now()
    )
    updated_at: Mapped[datetime] = mapped_column(
        TIMESTAMP, server_default=func.now(), onupdate=func.now()
    )

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ç–∞–±–ª–∏—Ü—ã
    @classmethod
    @property
    def __tablename__(cls) -> str:
        return cls.__name__.lower() + 's'


================================================
FILE: bot/dao/database_middleware.py
================================================
from typing import Callable, Dict, Any, Awaitable
from aiogram import BaseMiddleware
from aiogram.types import Message, CallbackQuery
from bot.dao.database import async_session_maker

class BaseDatabaseMiddleware(BaseMiddleware):
    async def __call__(
        self,
        handler: Callable[[Message | CallbackQuery, Dict[str, Any]], Awaitable[Any]],
        event: Message | CallbackQuery,
        data: Dict[str, Any]
    ) -> Any:
        async with async_session_maker() as session:
            self.set_session(data, session)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Å—Å–∏—é
            try:
                result = await handler(event, data)  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏–µ
                await self.after_handler(session)  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–º–º–∏—Ç)
                return result
            except Exception as e:
                await session.rollback()  # –û—Ç–∫–∞—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                raise e
            finally:
                await session.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é

    def set_session(self, data: Dict[str, Any], session) -> None:
        """–ú–µ—Ç–æ–¥ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–µ—Å—Å–∏–∏ –≤ –¥–∞–Ω–Ω—ã–µ. –†–µ–∞–ª–∏–∑—É–µ—Ç—Å—è –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö –∫–ª–∞—Å—Å–∞—Ö."""
        raise NotImplementedError("–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –ø–æ–¥–∫–ª–∞—Å—Å–∞—Ö.")

    async def after_handler(self, session) -> None:
        """–ú–µ—Ç–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏–π –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏—è. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç."""
        pass


class DatabaseMiddlewareWithoutCommit(BaseDatabaseMiddleware):
    def set_session(self, data: Dict[str, Any], session) -> None:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Å—Å–∏—é –±–µ–∑ –∫–æ–º–º–∏—Ç–∞."""
        data['session_without_commit'] = session

class DatabaseMiddlewareWithCommit(BaseDatabaseMiddleware):
    def set_session(self, data: Dict[str, Any], session) -> None:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Å—Å–∏—é —Å –∫–æ–º–º–∏—Ç–æ–º."""
        data['session_with_commit'] = session

    async def after_handler(self, session) -> None:
        """–§–∏–∫—Å–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏—è."""
        await session.commit()


================================================
FILE: bot/dao/models.py
================================================
from typing import List
from sqlalchemy.orm import Mapped, mapped_column, relationship
from sqlalchemy import BigInteger, Boolean, Float, Integer, String, Text, ForeignKey
from bot.dao.database import Base


from sqlalchemy import UniqueConstraint
from sqlalchemy.orm import Mapped, mapped_column, relationship
from sqlalchemy import ForeignKey, Text, BigInteger
from bot.dao.database import Base

# –ï—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, –¥–æ–±–∞–≤—å—Ç–µ —Å–≤—è–∑–∏ favorites –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –º–æ–¥–µ–ª—è–º User –∏ Product


class User(Base):
    telegram_id: Mapped[int] = mapped_column(BigInteger, unique=True, nullable=False)
    username: Mapped[str | None]
    first_name: Mapped[str | None]
    last_name: Mapped[str | None]

    def __repr__(self):
        return f"<User(id={self.id}, telegram_id={self.telegram_id}, username='{self.username}')>"


class Product(Base):
    __tablename__ = 'products'

    offer_id: Mapped[int] = mapped_column(Integer, unique=True, nullable=False)
    url: Mapped[str] = mapped_column(String, nullable=False)
    price: Mapped[float] = mapped_column(Float)
    currency: Mapped[str] = mapped_column(String(10))
    category_id: Mapped[int] = mapped_column(Integer)
    name: Mapped[str] = mapped_column(String)
    model: Mapped[str] = mapped_column(String)
    vendor: Mapped[str] = mapped_column(String)
    vendor_code: Mapped[str] = mapped_column(String)
    description: Mapped[str] = mapped_column(Text)
    warranty: Mapped[bool] = mapped_column(Boolean, default=False)
    pictures: Mapped[str] = mapped_column(Text)  # –≤–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏
    wholesale_price: Mapped[float] = mapped_column(Float)
    bestseller: Mapped[bool] = mapped_column(Boolean, default=False)
    unit: Mapped[str] = mapped_column(String(10))
    price_ue: Mapped[float] = mapped_column(Float)
    stock_moscow_chashnikovo: Mapped[str] = mapped_column(String)  # —Å—Ç—Ä–æ–∫–∞ —Ç–∏–ø–∞ "–±–æ–ª–µ–µ 100"
    stock_moscow_kantemirovskaya: Mapped[int] = mapped_column(Integer)
    stock_spb: Mapped[int] = mapped_column(Integer)
    stock_voronezh: Mapped[int] = mapped_column(Integer)
    price_legal_by: Mapped[float] = mapped_column(Float)
    price_individual_by: Mapped[float] = mapped_column(Float)
    availability: Mapped[str] = mapped_column(String(20))  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "–µ—Å—Ç—å"
    product_status: Mapped[str] = mapped_column(String(50))

class Favorite(Base):
    __tablename__ = 'favorites'
    __table_args__ = (UniqueConstraint("user_id", "product_id", name="unique_favorite"),)

    user_id: Mapped[int] = mapped_column(ForeignKey('users.id'))
    product_id: Mapped[int] = mapped_column(ForeignKey('products.id'))

    user: Mapped["User"] = relationship("User", backref="favorites")
    product: Mapped["Product"] = relationship("Product", backref="favorited_by")



================================================
FILE: bot/migration/README
================================================
Generic single-database configuration with an async dbapi.


================================================
FILE: bot/migration/env.py
================================================
from os.path import abspath, dirname
import sys

sys.path.insert(0, dirname(dirname(abspath(__file__))))

import asyncio
from logging.config import fileConfig
from sqlalchemy import pool
from sqlalchemy.engine import Connection
from bot.config import database_url
from sqlalchemy.ext.asyncio import async_engine_from_config
from bot.dao.database import Base
from alembic import context
from bot.dao.models import User

config = context.config
config.set_main_option("sqlalchemy.url", database_url)

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection: Connection) -> None:
    context.configure(connection=connection, target_metadata=target_metadata)

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations() -> None:
    """In this scenario we need to create an Engine
    and associate a connection with the context.

    """

    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""

    asyncio.run(run_async_migrations())


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()



================================================
FILE: bot/migration/script.py.mako
================================================
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    """Upgrade schema."""
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    """Downgrade schema."""
    ${downgrades if downgrades else "pass"}



================================================
FILE: bot/migration/versions/8fe99a9f0146_new_products.py
================================================
"""New Products

Revision ID: 8fe99a9f0146
Revises: 
Create Date: 2025-04-09 21:54:32.194247

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '8fe99a9f0146'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('products',
    sa.Column('offer_id', sa.Integer(), nullable=False),
    sa.Column('url', sa.String(), nullable=False),
    sa.Column('price', sa.Float(), nullable=False),
    sa.Column('currency', sa.String(length=10), nullable=False),
    sa.Column('category_id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('model', sa.String(), nullable=False),
    sa.Column('vendor', sa.String(), nullable=False),
    sa.Column('vendor_code', sa.String(), nullable=False),
    sa.Column('description', sa.Text(), nullable=False),
    sa.Column('warranty', sa.Boolean(), nullable=False),
    sa.Column('pictures', sa.Text(), nullable=False),
    sa.Column('wholesale_price', sa.Float(), nullable=False),
    sa.Column('bestseller', sa.Boolean(), nullable=False),
    sa.Column('unit', sa.String(length=10), nullable=False),
    sa.Column('price_ue', sa.Float(), nullable=False),
    sa.Column('stock_moscow_chashnikovo', sa.String(), nullable=False),
    sa.Column('stock_moscow_kantemirovskaya', sa.Integer(), nullable=False),
    sa.Column('stock_spb', sa.Integer(), nullable=False),
    sa.Column('stock_voronezh', sa.Integer(), nullable=False),
    sa.Column('price_legal_by', sa.Float(), nullable=False),
    sa.Column('price_individual_by', sa.Float(), nullable=False),
    sa.Column('availability', sa.String(length=20), nullable=False),
    sa.Column('product_status', sa.String(length=50), nullable=False),
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('offer_id')
    )
    op.create_table('users',
    sa.Column('telegram_id', sa.BigInteger(), nullable=False),
    sa.Column('username', sa.String(), nullable=True),
    sa.Column('first_name', sa.String(), nullable=True),
    sa.Column('last_name', sa.String(), nullable=True),
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('telegram_id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('users')
    op.drop_table('products')
    # ### end Alembic commands ###



================================================
FILE: bot/migration/versions/d14ca4f76ccf_add_favorites_table.py
================================================
"""add favorites table

Revision ID: d14ca4f76ccf
Revises: 8fe99a9f0146
Create Date: 2025-04-10 12:16:28.008660

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'd14ca4f76ccf'
down_revision: Union[str, None] = '8fe99a9f0146'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('favorites',
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('product_id', sa.Integer(), nullable=False),
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['product_id'], ['products.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('user_id', 'product_id', name='unique_favorite')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('favorites')
    # ### end Alembic commands ###



================================================
FILE: bot/user/__init__.py
================================================
[Empty file]


================================================
FILE: bot/user/kbs.py
================================================
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.utils.keyboard import InlineKeyboardBuilder
from bot.config import settings


def main_user_kb() -> InlineKeyboardMarkup:
    kb = InlineKeyboardBuilder()
    kb.button(text="üë§ –ò–∑–±—Ä–∞–Ω–Ω–æ–µ", callback_data="favorites")
    kb.button(text="üõç –ü–æ–∏—Å–∫ –ø–æ —Ç–æ–≤–∞—Ä–∞–º", callback_data="search")
    kb.button(text="üìû  –ü–æ–¥–¥–µ—Ä–∂–∫–∞", callback_data="support")
    # if user_id in settings.ADMIN_IDS:
    #     kb.button(text="‚öôÔ∏è –ê–¥–º–∏–Ω –ø–∞–Ω–µ–ª—å", callback_data="admin_panel")
    kb.adjust(1)
    return kb.as_markup()

def purchases_kb() -> InlineKeyboardMarkup:
    kb = InlineKeyboardBuilder()
    kb.button(text="üóë –°–º–æ—Ç—Ä–µ—Ç—å –ø–æ–∫—É–ø–∫–∏", callback_data="purchases")
    kb.button(text="üè† –ù–∞ –≥–ª–∞–≤–Ω—É—é", callback_data="home")
    kb.adjust(1)
    return kb.as_markup()


def product_kb(product_id, price, is_favorite: bool = False) -> InlineKeyboardMarkup:
    kb = InlineKeyboardBuilder()
    kb.button(text="üí∏ –ö—É–ø–∏—Ç—å", callback_data=f"buy_{product_id}_{price}")
    if is_favorite:
        kb.button(text="‚ùå –£–¥–∞–ª–∏—Ç—å –∏–∑ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ", callback_data=f"removefav_{product_id}")
    else:
        kb.button(text="‚≠ê –í –∏–∑–±—Ä–∞–Ω–Ω–æ–µ", callback_data=f"addfav_{product_id}")
    kb.button(text="üè† –ù–∞ –≥–ª–∞–≤–Ω—É—é", callback_data="home")
    kb.adjust(1)
    return kb.as_markup()


def get_product_buy_kb(price) -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text=f'–û–ø–ª–∞—Ç–∏—Ç—å {price}‚ÇΩ', pay=True)],
        [InlineKeyboardButton(text='–û—Ç–º–µ–Ω–∏—Ç—å', callback_data='home')]
    ])


================================================
FILE: bot/user/schemas.py
================================================

from pydantic import BaseModel, ConfigDict


class TelegramIDModel(BaseModel):
    telegram_id: int

    model_config = ConfigDict(from_attributes=True)


class UserModel(TelegramIDModel):
    username: str | None
    first_name: str | None
    last_name: str | None


class ProductIDModel(BaseModel):
    id: int


================================================
FILE: bot/user/user_router.py
================================================
from aiogram import Router, F
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.types import Message, CallbackQuery
from sqlalchemy.ext.asyncio import AsyncSession
from bot.dao.dao import FavoriteDAO, ProductDao, UserDAO
from bot.user.kbs import main_user_kb, product_kb
from bot.user.schemas import TelegramIDModel, UserModel

user_router = Router()

class SearchState(StatesGroup):
    user_search_request = State()
    
@user_router.message(CommandStart())
async def cmd_start(message: Message, session_with_commit: AsyncSession):
    user_id = message.from_user.id
    user_info = await UserDAO.find_one_or_none(
        session=session_with_commit,
        filters=TelegramIDModel(telegram_id=user_id)
    )

    if user_info:
        return await message.answer(
            f"üëã –ü—Ä–∏–≤–µ—Ç, {message.from_user.full_name}! –í—ã–±–µ—Ä–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ",
            reply_markup=main_user_kb()
        )

    values = UserModel(
        telegram_id=user_id,
        username=message.from_user.username,
        first_name=message.from_user.first_name,
        last_name=message.from_user.last_name,
    )
    await UserDAO.add(session=session_with_commit, values=values)
    await message.answer("üéâ <b>–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é!</b>. –¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ.",
                         reply_markup=main_user_kb())


@user_router.callback_query(F.data == 'search')
async def search_products(callback: CallbackQuery, state: FSMContext):
    await callback.message.answer(text='–í–≤–µ–¥–∏—Ç–µ <b>–∞—Ä—Ç–∏–∫—É–ª</b> —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä.')

    await state.set_state(SearchState.user_search_request)

    await callback.answer('')

@user_router.message(SearchState.user_search_request)
async def proces_user_search(message: Message, state: FSMContext, session_without_commit: AsyncSession):
    await state.clear()

    vendor_code = message.text.strip()
    
    product = await ProductDao.find_one_or_none_by_vendor_code(vendor_code, session_without_commit)

    if product:
        response = (
            f"<b>–ù–∞–∑–≤–∞–Ω–∏–µ:</b> {product.name}\n\n"
            f"<b>–û–ø–∏—Å–∞–Ω–∏–µ:</b> {product.description}\n\n"
            f"<b>–¶–µ–Ω–∞:</b> {product.price}‚ÇΩ"
        )
        await message.answer(text=response, reply_markup=product_kb(product_id=product.id, price=product.price))
    else:
        await message.answer(text="‚ùå –¢–æ–≤–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.", reply_markup=main_user_kb())
        
@user_router.callback_query(F.data == 'favorites')
async def show_favorites(callback: CallbackQuery, session_without_commit: AsyncSession):
    user_id = callback.from_user.id

    user = await UserDAO.find_one_or_none(
        session=session_without_commit,
        filters=TelegramIDModel(telegram_id=user_id)
    )

    if not user:
        return await callback.message.answer("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    favorites = await FavoriteDAO.get_user_favorites(user.id, session=session_without_commit)

    if not favorites:
        return await callback.message.answer("–£ –≤–∞—Å –Ω–µ—Ç –∏–∑–±—Ä–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤.", reply_markup=main_user_kb())

    for fav in favorites:
        product = await ProductDao.find_one_or_none_by_id(fav.product_id, session=session_without_commit)
        if product:
            text = f"<b>{product.name}</b>\n{product.description}\n–¶–µ–Ω–∞: {product.price} BYN"
            await callback.message.answer(
                text,
                reply_markup=product_kb(product.id, product.price, is_favorite=True)
            )
            

@user_router.callback_query(F.data.startswith("addfav_"))
async def add_to_favorites(callback: CallbackQuery, session_with_commit: AsyncSession):
    product_id = int(callback.data.split("_")[1])
    user_telegram_id = callback.from_user.id

    user = await UserDAO.find_one_or_none(session=session_with_commit, filters=TelegramIDModel(telegram_id=user_telegram_id))
    if not user:
        return await callback.answer("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    await FavoriteDAO.add_favorite(user.id, product_id, session=session_with_commit)
    await callback.answer("–î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∏–∑–±—Ä–∞–Ω–Ω–æ–µ ‚ù§Ô∏è")

    # –û–±–Ω–æ–≤–∏—Ç—å –∫–∞—Ä—Ç–æ—á–∫—É
    product = await ProductDao.find_one_or_none_by_id(product_id, session=session_with_commit)
    if product:
        text = f"<b>{product.name}</b>\n{product.description}\n–¶–µ–Ω–∞: {product.price} BYN"
        await callback.message.edit_text(text, reply_markup=product_kb(product.id, product.price, is_favorite=True))


@user_router.callback_query(F.data.startswith("removefav_"))
async def remove_from_favorites(callback: CallbackQuery, session_with_commit: AsyncSession):
    product_id = int(callback.data.split("_")[1])
    user_telegram_id = callback.from_user.id

    user = await UserDAO.find_one_or_none(session=session_with_commit, filters=TelegramIDModel(telegram_id=user_telegram_id))
    if not user:
        return await callback.answer("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    await FavoriteDAO.remove_favorite(user.id, product_id, session=session_with_commit)
    await callback.answer("–£–¥–∞–ª–µ–Ω–æ –∏–∑ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ üíî")

    product = await ProductDao.find_one_or_none_by_id(product_id, session=session_with_commit)
    if product:
        text = f"<b>{product.name}</b>\n{product.description}\n–¶–µ–Ω–∞: {product.price} BYN"
        await callback.message.edit_text(text, reply_markup=product_kb(product.id, product.price, is_favorite=False))


